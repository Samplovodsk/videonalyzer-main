# ü§ñ –†–µ—Å—É—Ä—Å—ã –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è

## üìä –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ YOLO

### –ë–æ–ª–µ–µ —Ç–æ—á–Ω—ã–µ –º–æ–¥–µ–ª–∏
```python
# –í config.py –º–æ–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å –º–æ–¥–µ–ª—å –Ω–∞ –±–æ–ª–µ–µ —Ç–æ—á–Ω—É—é
YOLO_MODEL = 'yolov8s.pt'  # –°—Ä–µ–¥–Ω—è—è —Ç–æ—á–Ω–æ—Å—Ç—å, –±—ã—Å—Ç—Ä–∞—è
YOLO_MODEL = 'yolov8m.pt'  # –í—ã—Å–æ–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å, —Å—Ä–µ–¥–Ω—è—è —Å–∫–æ—Ä–æ—Å—Ç—å
YOLO_MODEL = 'yolov8l.pt'  # –û—á–µ–Ω—å –≤—ã—Å–æ–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å, –º–µ–¥–ª–µ–Ω–Ω–∞—è
YOLO_MODEL = 'yolov8x.pt'  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å, –æ—á–µ–Ω—å –º–µ–¥–ª–µ–Ω–Ω–∞—è
```

### –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
```python
# –î–µ—Ç–µ–∫—Ü–∏—è –ª—é–¥–µ–π
YOLO_MODEL = 'yolov8n-pose.pt'  # –î–µ—Ç–µ–∫—Ü–∏—è –ø–æ–∑ —á–µ–ª–æ–≤–µ–∫–∞

# –î–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü
YOLO_MODEL = 'yolov8n-face.pt'  # –î–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü
```

## üîß –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫

### –£—Å–∫–æ—Ä–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
```bash
# CUDA –¥–ª—è GPU —É—Å–∫–æ—Ä–µ–Ω–∏—è
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# TensorRT –¥–ª—è NVIDIA GPU
pip install tensorrt

# OpenVINO –¥–ª—è Intel CPU/GPU
pip install openvino
```

### –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏
```bash
# Detectron2 –æ—Ç Facebook
pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu118/torch2.0/index.html

# MediaPipe –æ—Ç Google
pip install mediapipe

# YOLOv5 (–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞)
pip install ultralytics
```

### –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ
```bash
# FFmpeg –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –≤–∏–¥–µ–æ
pip install ffmpeg-python

# VideoIO –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –≤–∏–¥–µ–æ—Ñ–∞–π–ª–∞–º–∏
pip install imageio[ffmpeg]

# OpenCV —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –º–æ–¥—É–ª—è–º–∏
pip install opencv-contrib-python
```

## üìö –û–±—É—á–µ–Ω–∏–µ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏

### 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö

#### –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞
```python
# –ü—Ä–∏–º–µ—Ä —Å–æ–∑–¥–∞–Ω–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π
import cv2
import json
import os

def create_dataset():
    # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫
    os.makedirs('dataset/images', exist_ok=True)
    os.makedirs('dataset/labels', exist_ok=True)
    
    # –ê–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ YOLO
    annotations = {
        'person': 0,
        'knife': 1,
        'gun': 2,
        'bottle': 3,
        'suspicious_behavior': 4
    }
    
    return annotations
```

#### –ê–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
```python
# –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è –∞–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:
# - LabelImg: https://github.com/tzutalin/labelImg
# - CVAT: https://github.com/openvinotoolkit/cvat
# - Roboflow: https://roboflow.com/
```

### 2. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏

#### –û–±—É—á–µ–Ω–∏–µ YOLO
```python
from ultralytics import YOLO

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å
model = YOLO('yolov8n.pt')

# –û–±—É—á–∞–µ–º –Ω–∞ —Å–≤–æ–∏—Ö –¥–∞–Ω–Ω—ã—Ö
results = model.train(
    data='dataset.yaml',  # –§–∞–π–ª –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞
    epochs=100,
    imgsz=640,
    batch=16,
    device='cuda'  # –ò—Å–ø–æ–ª—å–∑—É–µ–º GPU –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
)

# –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å
model.save('custom_model.pt')
```

#### –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞ (dataset.yaml)
```yaml
# dataset.yaml
path: ./dataset
train: images/train
val: images/val
test: images/test

nc: 5  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤
names: ['person', 'knife', 'gun', 'bottle', 'suspicious_behavior']
```

### 3. –§–∞–π–Ω-—Ç—é–Ω–∏–Ω–≥ –º–æ–¥–µ–ª–∏

#### –ê–¥–∞–ø—Ç–∞—Ü–∏—è –ø–æ–¥ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —É—Å–ª–æ–≤–∏—è
```python
# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –æ–±—É—á–µ–Ω–∏—è
model.train(
    data='dataset.yaml',
    epochs=50,
    imgsz=640,
    batch=8,
    lr0=0.01,  # –ù–∞—á–∞–ª—å–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è
    momentum=0.937,
    weight_decay=0.0005,
    warmup_epochs=3,
    warmup_momentum=0.8,
    warmup_bias_lr=0.1,
    box=7.5,
    cls=0.5,
    dfl=1.5,
    pose=12.0,
    kobj=2.0,
    label_smoothing=0.0,
    nbs=64,
    overlap_mask=True,
    mask_ratio=4,
    dropout=0.0,
    val=True,
    plots=True
)
```

## üéØ –£–ª—É—á—à–µ–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏ –¥–µ—Ç–µ–∫—Ü–∏–∏

### 1. –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
```python
# –í video_processor.py –¥–æ–±–∞–≤–∏—Ç—å –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É
def preprocess_frame(frame):
    # –£–ª—É—á—à–µ–Ω–∏–µ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞
    frame = cv2.convertScaleAbs(frame, alpha=1.2, beta=10)
    
    # –®—É–º–æ–ø–æ–¥–∞–≤–ª–µ–Ω–∏–µ
    frame = cv2.bilateralFilter(frame, 9, 75, 75)
    
    # –£–≤–µ–ª–∏—á–µ–Ω–∏–µ —Ä–µ–∑–∫–æ—Å—Ç–∏
    kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])
    frame = cv2.filter2D(frame, -1, kernel)
    
    return frame
```

### 2. –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
```python
# –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ª–æ–∂–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π
def filter_detections(detections, confidence_threshold=0.5):
    filtered = []
    for detection in detections:
        if detection['confidence'] > confidence_threshold:
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
            if detection['class'] == 'person':
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —á–µ–ª–æ–≤–µ–∫–∞
                bbox = detection['bbox']
                width = bbox[2] - bbox[0]
                height = bbox[3] - bbox[1]
                if height > 50:  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —á–µ–ª–æ–≤–µ–∫–∞
                    filtered.append(detection)
            else:
                filtered.append(detection)
    return filtered
```

### 3. –¢—Ä–µ–∫–∏–Ω–≥ –æ–±—ä–µ–∫—Ç–æ–≤
```python
# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ç—Ä–µ–∫–∏–Ω–≥–∞ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
from collections import defaultdict
import numpy as np

class ObjectTracker:
    def __init__(self):
        self.tracks = defaultdict(list)
        self.next_id = 0
    
    def update(self, detections):
        # –ü—Ä–æ—Å—Ç–æ–π —Ç—Ä–µ–∫–∏–Ω–≥ –ø–æ IoU
        for detection in detections:
            # –õ–æ–≥–∏–∫–∞ —Ç—Ä–µ–∫–∏–Ω–≥–∞
            pass
        return tracked_objects
```

## üìä –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞—Ç–∞—Å–µ—Ç—ã

### –ü—É–±–ª–∏—á–Ω—ã–µ –¥–∞—Ç–∞—Å–µ—Ç—ã
```python
# COCO Dataset - 80 –∫–ª–∞—Å—Å–æ–≤ –æ–±—ä–µ–∫—Ç–æ–≤
# –°–∫–∞—á–∞—Ç—å: https://cocodataset.org/

# Open Images Dataset - 600 –∫–ª–∞—Å—Å–æ–≤
# –°–∫–∞—á–∞—Ç—å: https://storage.googleapis.com/openimages/web/index.html

# Pascal VOC - 20 –∫–ª–∞—Å—Å–æ–≤
# –°–∫–∞—á–∞—Ç—å: http://host.robots.ox.ac.uk/pascal/VOC/

# Custom Security Dataset
# –°–æ–∑–¥–∞—Ç—å —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –Ω–∞—Ä—É—à–µ–Ω–∏–π
```

### –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞—Ç–∞—Å–µ—Ç—ã
```python
# –î–µ—Ç–µ–∫—Ü–∏—è –æ—Ä—É–∂–∏—è
# - Gun Detection Dataset
# - Weapon Detection Dataset

# –î–µ—Ç–µ–∫—Ü–∏—è –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø–æ–≤–µ–¥–µ–Ω–∏—è
# - Suspicious Activity Detection Dataset
# - Anomaly Detection Dataset
```

## üöÄ –û–±–ª–∞—á–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã

### Google Colab
```python
# –ë–µ—Å–ø–ª–∞—Ç–Ω—ã–π GPU –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
# https://colab.research.google.com/

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ Colab
!pip install ultralytics
from ultralytics import YOLO
model = YOLO('yolov8n.pt')
results = model.train(data='dataset.yaml', epochs=100)
```

### AWS SageMaker
```python
# –û–±–ª–∞—á–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
# https://aws.amazon.com/sagemaker/

# –ü—Ä–∏–º–µ—Ä –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
training_config = {
    'instance_type': 'ml.p3.2xlarge',
    'framework': 'pytorch',
    'framework_version': '1.12.1',
    'py_version': 'py38'
}
```

### Microsoft Azure ML
```python
# –û–±–ª–∞—á–Ω–∞—è –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞ –¥–ª—è ML
# https://azure.microsoft.com/en-us/products/machine-learning

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
from azureml.core import Workspace, Experiment
ws = Workspace.from_config()
experiment = Experiment(workspace=ws, name='video-analysis')
```

## üîß –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

### 1. –ö–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
```python
# –£–º–µ–Ω—å—à–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –º–æ–¥–µ–ª–∏
import torch
from ultralytics import YOLO

model = YOLO('yolov8n.pt')
# –ö–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
model.quantize()
```

### 2. –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è –º–æ–±–∏–ª—å–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤
```python
# –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ ONNX
model.export(format='onnx')

# –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ TensorFlow Lite
model.export(format='tflite')
```

### 3. –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
```python
# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö GPU
model.train(data='dataset.yaml', device=[0, 1, 2, 3])

# –ú–Ω–æ–≥–æ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
from multiprocessing import Pool
import cv2

def process_frame(frame):
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–∞
    return processed_frame

with Pool(4) as p:
    results = p.map(process_frame, frames)
```

## üìà –ú–µ—Ç—Ä–∏–∫–∏ –∏ –æ—Ü–µ–Ω–∫–∞

### –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
```python
# mAP (mean Average Precision)
# Precision –∏ Recall
# F1-Score
# IoU (Intersection over Union)

def calculate_metrics(predictions, ground_truth):
    # –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫
    precision = true_positives / (true_positives + false_positives)
    recall = true_positives / (true_positives + false_negatives)
    f1_score = 2 * (precision * recall) / (precision + recall)
    return precision, recall, f1_score
```

### –í–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
```python
# –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è
from sklearn.model_selection import KFold

kf = KFold(n_splits=5, shuffle=True, random_state=42)
for train_idx, val_idx in kf.split(dataset):
    # –û–±—É—á–µ–Ω–∏–µ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è
    pass
```

## üéØ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é

### 1. –î–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –±–æ–ª–µ–µ —Ç–æ—á–Ω—ã–µ –º–æ–¥–µ–ª–∏ (yolov8m, yolov8l)
- –£–≤–µ–ª–∏—á—å—Ç–µ —Ä–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞
- –î–æ–±–∞–≤—å—Ç–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—é –¥–∞–Ω–Ω—ã—Ö
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∞–Ω—Å–∞–º–±–ª–∏ –º–æ–¥–µ–ª–µ–π

### 2. –î–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è —Å–∫–æ—Ä–æ—Å—Ç–∏
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –±–æ–ª–µ–µ –±—ã—Å—Ç—Ä—ã–µ –º–æ–¥–µ–ª–∏ (yolov8n)
- –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–π—Ç–µ —Ä–∞–∑–º–µ—Ä –≤—Ö–æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ GPU —É—Å–∫–æ—Ä–µ–Ω–∏–µ
- –ü—Ä–∏–º–µ–Ω–∏—Ç–µ –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—é –º–æ–¥–µ–ª–∏

### 3. –î–ª—è —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏—Ö –∑–∞–¥–∞—á
- –û–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å –Ω–∞ —Å–≤–æ–∏—Ö –¥–∞–Ω–Ω—ã—Ö
- –î–æ–±–∞–≤—å—Ç–µ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–ª–∞—Å—Å—ã
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ transfer learning
- –ü—Ä–∏–º–µ–Ω–∏—Ç–µ domain adaptation

## üìö –ü–æ–ª–µ–∑–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã

### –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
- [Ultralytics YOLO](https://docs.ultralytics.com/)
- [OpenCV Documentation](https://docs.opencv.org/)
- [PyTorch Documentation](https://pytorch.org/docs/)

### –¢—É—Ç–æ—Ä–∏–∞–ª—ã
- [YOLO Tutorial](https://github.com/ultralytics/yolov5)
- [Computer Vision Tutorials](https://opencv-python-tutroals.readthedocs.io/)
- [Deep Learning for Computer Vision](https://cs231n.stanford.edu/)

### –°–æ–æ–±—â–µ—Å—Ç–≤–∞
- [YOLO Community](https://github.com/ultralytics/yolov5/discussions)
- [OpenCV Community](https://opencv.org/)
- [PyTorch Community](https://discuss.pytorch.org/)
